{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Learning objectives\nIn this lab, you will learn how to use generative AI to create Python codes that can:\n\n1. Use linear regression in one variable to fit the parameters to a model\n2. Use linear regression in multiple variables to fit the parameters to a model\n3. Use polynomial regression in a single variable to fit the parameters to a model\n4. Create a pipeline for performing linear regression using multiple features in polynomial scaling\n5. Use the grid search with cross-validation and ridge regression to create a model with optimum hyperparameters",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.pipeline import make_pipeline",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "# Keep appending the code generated to this cell, or add more cells below this to execute in parts\nimport pandas as pd\n\n# Specify the file path of the CSV file\nfile_path = \"dataset.csv\"\n\n# Read the CSV file into a Pandas data frame\ndata = pd.read_csv(file_path)\n\n# Display the first few rows of the data frame\nprint(data.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "   Unnamed: 0.1  Unnamed: 0 Manufacturer  Category  GPU  OS  CPU_core  \\\n0             0           0         Acer         4    2   1         5   \n1             1           1         Dell         3    1   1         3   \n2             2           2         Dell         3    1   1         7   \n3             3           3         Dell         4    2   1         5   \n4             4           4           HP         4    2   1         7   \n\n   Screen_Size_inch  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_pounds  \\\n0              14.0       0.551724       8             256        3.52800   \n1              15.6       0.689655       4             256        4.85100   \n2              15.6       0.931034       8             256        4.85100   \n3              13.3       0.551724       8             128        2.69010   \n4              15.6       0.620690       8             256        4.21155   \n\n   Price Price-binned  Screen-Full_HD  Screen-IPS_panel  \n0    978          Low               0                 1  \n1    634          Low               1                 0  \n2    946          Low               1                 0  \n3   1244          Low               0                 1  \n4    837          Low               1                 0  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "data",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     Unnamed: 0.1  Unnamed: 0 Manufacturer  Category  GPU  OS  CPU_core  \\\n0               0           0         Acer         4    2   1         5   \n1               1           1         Dell         3    1   1         3   \n2               2           2         Dell         3    1   1         7   \n3               3           3         Dell         4    2   1         5   \n4               4           4           HP         4    2   1         7   \n..            ...         ...          ...       ...  ...  ..       ...   \n233           233         233       Lenovo         4    2   1         7   \n234           234         234      Toshiba         3    2   1         5   \n235           235         235       Lenovo         4    2   1         5   \n236           236         236       Lenovo         3    3   1         5   \n237           237         237      Toshiba         3    2   1         5   \n\n     Screen_Size_inch  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_pounds  \\\n0                14.0       0.551724       8             256        3.52800   \n1                15.6       0.689655       4             256        4.85100   \n2                15.6       0.931034       8             256        4.85100   \n3                13.3       0.551724       8             128        2.69010   \n4                15.6       0.620690       8             256        4.21155   \n..                ...            ...     ...             ...            ...   \n233              14.0       0.896552       8             256        3.74850   \n234              13.3       0.827586       8             256        2.64600   \n235              12.0       0.896552       8             256        2.99880   \n236              15.6       0.862069       6             256        5.29200   \n237              14.0       0.793103       8             256        4.29975   \n\n     Price Price-binned  Screen-Full_HD  Screen-IPS_panel  \n0      978          Low               0                 1  \n1      634          Low               1                 0  \n2      946          Low               1                 0  \n3     1244          Low               0                 1  \n4      837          Low               1                 0  \n..     ...          ...             ...               ...  \n233   1891       Medium               0                 1  \n234   1950       Medium               1                 0  \n235   2236       Medium               0                 1  \n236    883          Low               1                 0  \n237   1499          Low               1                 0  \n\n[238 rows x 16 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>Manufacturer</th>\n      <th>Category</th>\n      <th>GPU</th>\n      <th>OS</th>\n      <th>CPU_core</th>\n      <th>Screen_Size_inch</th>\n      <th>CPU_frequency</th>\n      <th>RAM_GB</th>\n      <th>Storage_GB_SSD</th>\n      <th>Weight_pounds</th>\n      <th>Price</th>\n      <th>Price-binned</th>\n      <th>Screen-Full_HD</th>\n      <th>Screen-IPS_panel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Acer</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>14.0</td>\n      <td>0.551724</td>\n      <td>8</td>\n      <td>256</td>\n      <td>3.52800</td>\n      <td>978</td>\n      <td>Low</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15.6</td>\n      <td>0.689655</td>\n      <td>4</td>\n      <td>256</td>\n      <td>4.85100</td>\n      <td>634</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>15.6</td>\n      <td>0.931034</td>\n      <td>8</td>\n      <td>256</td>\n      <td>4.85100</td>\n      <td>946</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>Dell</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>13.3</td>\n      <td>0.551724</td>\n      <td>8</td>\n      <td>128</td>\n      <td>2.69010</td>\n      <td>1244</td>\n      <td>Low</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>HP</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>15.6</td>\n      <td>0.620690</td>\n      <td>8</td>\n      <td>256</td>\n      <td>4.21155</td>\n      <td>837</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>233</th>\n      <td>233</td>\n      <td>233</td>\n      <td>Lenovo</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>14.0</td>\n      <td>0.896552</td>\n      <td>8</td>\n      <td>256</td>\n      <td>3.74850</td>\n      <td>1891</td>\n      <td>Medium</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>234</td>\n      <td>234</td>\n      <td>Toshiba</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>13.3</td>\n      <td>0.827586</td>\n      <td>8</td>\n      <td>256</td>\n      <td>2.64600</td>\n      <td>1950</td>\n      <td>Medium</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>235</td>\n      <td>235</td>\n      <td>Lenovo</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>12.0</td>\n      <td>0.896552</td>\n      <td>8</td>\n      <td>256</td>\n      <td>2.99880</td>\n      <td>2236</td>\n      <td>Medium</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>236</td>\n      <td>236</td>\n      <td>Lenovo</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>5</td>\n      <td>15.6</td>\n      <td>0.862069</td>\n      <td>6</td>\n      <td>256</td>\n      <td>5.29200</td>\n      <td>883</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>237</td>\n      <td>237</td>\n      <td>Toshiba</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>14.0</td>\n      <td>0.793103</td>\n      <td>8</td>\n      <td>256</td>\n      <td>4.29975</td>\n      <td>1499</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>238 rows Ã— 16 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### GAI prompt\nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses one attribute of a data frame as the source variable and another as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\n# Define your source and target variables\nX = data['CPU_frequency'].values.reshape(-1, 1)\ny = data['Price'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate MSE and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'Mean Squared Error: {mse}')\nprint(f'R^2 Score: {r2}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error: 239035.99429436037\nR^2 Score: -0.03719417833496452\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "### GAI prompt\nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses some attributes of a data frame as the source variables and one of the attributes as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define your source and target variables\nX = data[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = data['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate MSE and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'Mean Squared Error: {mse}')\nprint(f'R^2 Score: {r2}')\n\n# Optional: Display model coefficients\nprint(f\"Model Coefficients: {model.coef_}\")\nprint(f\"Model Intercept: {model.intercept_}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error: 168575.62043820194\nR^2 Score: 0.268538394630248\nModel Coefficients: [ 1.02371164e+03  9.87472705e+01  2.53360567e-02  7.57223770e+01\n -4.99870688e+02  1.30109742e+02  1.57678705e+02]\nModel Intercept: -806.6521520731142\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "### GAI prompt\n\nWrite a Python code that performs the following tasks.\n1. Develops and trains multiple polynomial regression models, with orders 2, 3, and 5, that use one attribute of a data frame as the source variable and another as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained models.\n3. Compare the performance of the models.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define your source and target variables\nX = data['CPU_frequency'].values.reshape(-1, 1)\ny = data['Price'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmse_values = []\nr2_values = []\n\n# Train polynomial regression models of different orders\norders = [2, 3, 5]\nfor order in orders:\n    poly_features = PolynomialFeatures(degree=order)\n    X_train_poly = poly_features.fit_transform(X_train)\n    X_test_poly = poly_features.transform(X_test)\n    \n    model = LinearRegression()\n    model.fit(X_train_poly, y_train)\n    \n    y_pred = model.predict(X_test_poly)\n    \n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    mse_values.append(mse)\n    r2_values.append(r2)\n    \n    print(f'Polynomial Order {order}:')\n    print(f'Mean Squared Error: {mse}')\n    print(f'R^2 Score: {r2}')\n    print('')\n\n# Compare the performance of the models\nbest_order = np.argmin(mse_values)\nworst_order = np.argmax(r2_values)\n\nprint(\"Model Comparison:\")\nprint(f\"Best Polynomial Order: {best_order + 2}\")\nprint(f\"Worst Polynomial Order: {worst_order + 2}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Polynomial Order 2:\nMean Squared Error: 196263.56145770708\nR^2 Score: 0.14839844951324532\n\nPolynomial Order 3:\nMean Squared Error: 205918.03020817842\nR^2 Score: 0.10650702302550674\n\nPolynomial Order 5:\nMean Squared Error: 207335.703609638\nR^2 Score: 0.10035563731845087\n\nModel Comparison:\nBest Polynomial Order: 2\nWorst Polynomial Order: 2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "### GAI prompt\n\nWrite a Python code that performs the following tasks.\n1. Create a pipeline that performs parameter scaling, Polynomial Feature generation, and Linear regression. Use the set of multiple features as before to create this pipeline.\n2. Calculate and display the MSE and R^2 values for the trained model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define your source and target variables\nX = data[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = data['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a pipeline for scaling, polynomial feature generation, and linear regression\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('poly_features', PolynomialFeatures(degree=2)),\n    ('linear_reg', LinearRegression())\n])\n\n# Fit the pipeline on the training data\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Calculate MSE and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'Mean Squared Error: {mse}')\nprint(f'R^2 Score: {r2}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error: 1.3363655519166364e+31\nR^2 Score: -5.798585165665274e+25\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "### GAI prompt\nWrite a Python code that performs the following tasks.\n1. Use polynomial features for some of the attributes of a data frame.\n2. Perform Grid search on a ridge regression model for a set of values of hyperparameter alpha and polynomial features as input.\n3. Use cross-validation in the Grid search.\n4. Evaluate the resulting model's MSE and R^2 values.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define your features and target variable\nX = data[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = data['Price']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a pipeline with polynomial features and Ridge regression\npipeline = make_pipeline(PolynomialFeatures(), Ridge())\n\n# Define the hyperparameters to search through\nparam_grid = {\n    'polynomialfeatures__degree': [2,3,4],\n    'ridge__alpha': [0.0001,0.001,0.01, 0.1, 1, 10]\n}\n\n# Perform Grid Search with cross-validation\ngrid_search = GridSearchCV(pipeline, param_grid, cv=4)\ngrid_search.fit(X_train, y_train)\n\n# Make predictions\ny_pred = grid_search.predict(X_test)\n\n# Calculate MSE and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n\nprint(f'Best parameters: {grid_search.best_params_}')\nprint(f'Mean Squared Error: {mse}')\nprint(f'R^2 Score: {r2}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=3.22899e-20): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=1.29308e-20): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.46463e-20): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.57277e-20): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=3.22625e-19): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=1.86245e-19): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.45648e-19): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.57081e-19): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=3.26062e-18): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=1.84621e-18): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.4477e-18): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.57678e-18): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=3.76275e-17): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=1.85094e-17): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.44655e-17): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.99491e-17): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:239: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Best parameters: {'polynomialfeatures__degree': 2, 'ridge__alpha': 10}\nMean Squared Error: 240003.5674572609\nR^2 Score: -0.04139254709794593\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "## Conclusion\nCongratulations! You have completed the lab on Data preparation.\n\nWith this, you have learned how to use generative AI to create Python codes that can:\n\n1. Implement linear regression in single variable\n2. Implement linear regression in multiple variables\n3. Implement polynomial regression for different orders of a single variable\n4. Create a pipeline that implements polynomial scaling for multiple variables and performs linear regression on them\n5. Apply a grid search to create an optimum ridge regression model for multiple features",
      "metadata": {}
    }
  ]
}